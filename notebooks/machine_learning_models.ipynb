{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24b1402a-ffb5-4fef-b4b5-7039eff0eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "575f1dd5-b1ba-4d7f-8529-6fa6e1dfee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PricePredictionPipeline:\n",
    "    def __init__(self, df, target_col=\"price\"):\n",
    "        self.df = df.copy()\n",
    "        self.target_col = target_col\n",
    "        self.models = {\n",
    "            \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "            \"GradientBoosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "            \"XGBoost\": xgb.XGBRegressor(n_estimators=100, random_state=42),\n",
    "            \"LightGBM\": lgb.LGBMRegressor(n_estimators=100, random_state=42),\n",
    "        }\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.best_model_name = None\n",
    "        # self.label_encoders = {}\n",
    "        # self.feature_cols = None\n",
    "        self.pipeline = None\n",
    "\n",
    "    def preprocess(self):\n",
    "        # Convert date\n",
    "        self.df['date'] = pd.to_datetime(self.df['date'])\n",
    "        self.df['year'] = self.df['date'].dt.year\n",
    "        self.df['month'] = self.df['date'].dt.month\n",
    "        self.df['dayofweek'] = self.df['date'].dt.dayofweek\n",
    "\n",
    "        # Drop unused columns\n",
    "        drop_cols = [\n",
    "            self.target_col,\n",
    "            \"usdprice\",\n",
    "            \"date\",\n",
    "            \"priceflag\",\n",
    "            \"admin2\",\n",
    "            \"market_id\",\n",
    "            \"commodity_id\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "        ]\n",
    "\n",
    "        # # Encode categorical features\n",
    "        # cat_cols = ['admin1', 'admin2', 'market', 'category', 'commodity',\n",
    "        #             'unit', 'pricetype', 'currency']\n",
    "        # for col in cat_cols:\n",
    "        #     le = LabelEncoder()\n",
    "        #     self.df[col] = le.fit_transform(self.df[col].astype(str))\n",
    "        #     self.label_encoders[col] = le  # save encoder for later use\n",
    "\n",
    "        # Define features and target\n",
    "        X = self.df.drop(columns=[c for c in drop_cols if c in self.df.columns])\n",
    "        y = self.df[self.target_col]\n",
    "\n",
    "        # #identify columns types\n",
    "        # cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "        # num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "        # self.feature_cols = X.columns.tolist()\n",
    "        return X, y\n",
    "\n",
    "    def split(self, X, y, test_size=0.2):\n",
    "        return train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "\n",
    "    def train_and_evaluate(self, X_train, X_test, y_train, y_test):\n",
    "        # #identify columns types\n",
    "        cat_cols = X_train.select_dtypes(include=\"object\").columns.tolist()\n",
    "        num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "        \n",
    "        #build preprocessing transformer\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "                (\"num\", \"passthrough\", num_cols)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            try:\n",
    "                pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                # model.fit(X_train, y_train)\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                r2score = r2_score(y_test, y_pred)\n",
    "                self.results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"R2 Score\": r2score}\n",
    "                self.models[name] = pipeline\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to train {name}: {e}\")\n",
    "\n",
    "        if not self.results:\n",
    "            raise RuntimeError(\"❌ All models failed to train. Please check data or library versions.\")\n",
    "\n",
    "        self.results = pd.DataFrame(self.results).T\n",
    "        self.best_model_name = self.results['RMSE'].idxmin()\n",
    "        self.best_model = self.models[self.best_model_name]\n",
    "        self.pipeline = self.best_model\n",
    "        return self.results\n",
    "\n",
    "    def plot_predictions(self, X_test, y_test):\n",
    "        if not self.best_model:\n",
    "            raise ValueError(\"No best model found. Run train_and_evaluate() first.\")\n",
    "        y_pred = self.best_model.predict(X_test)\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(y_test.values, label=\"Actual\", alpha=0.7)\n",
    "        plt.plot(y_pred, label=f\"Predicted ({self.best_model_name})\", alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.title(\"Actual vs Predicted Prices\")\n",
    "        plt.show()\n",
    "\n",
    "    def save_best_model(self, filename=\"best_model.pkl\"):\n",
    "        if not self.pipeline:\n",
    "            raise ValueError(\"No trained model found. Run train_and_evaluate() first.\")\n",
    "\n",
    "        # package = {\n",
    "        #     \"model\": self.best_model,\n",
    "        #     \"model_name\": self.best_model_name,\n",
    "        #     \"label_encoders\": self.label_encoders,\n",
    "        #     \"feature_cols\": self.feature_cols,\n",
    "        # }\n",
    "        joblib.dump(self.pipeline, filename)\n",
    "        print(f\"✅ Best model ({self.best_model_name}) saved as {filename}\")\n",
    "\n",
    "    def load_model(self, filename=\"best_model.pkl\"):\n",
    "        if not os.path.exists(filename):\n",
    "            raise FileNotFoundError(f\"{filename} not found.\")\n",
    "        self.pipeline = joblib.load(filename)\n",
    "        # self.best_model = package[\"model\"]\n",
    "        # self.best_model_name = package[\"model_name\"]\n",
    "        # self.label_encoders = package[\"label_encoders\"]\n",
    "        # self.feature_cols = package[\"feature_cols\"]\n",
    "        print(f\"✅ Loaded pipeline from {filename}\")\n",
    "        return self.pipeline\n",
    "\n",
    "    # def prepare_new_data(self, new_df):\n",
    "    #     \"\"\"Preprocess new unseen data using saved encoders & features\"\"\"\n",
    "    #     new_df = new_df.copy()\n",
    "    #     new_df['date'] = pd.to_datetime(new_df['date'])\n",
    "    #     new_df['year'] = new_df['date'].dt.year\n",
    "    #     new_df['month'] = new_df['date'].dt.month\n",
    "    #     new_df['dayofweek'] = new_df['date'].dt.dayofweek\n",
    "\n",
    "    #     # Apply saved label encoders\n",
    "    #     for col, le in self.label_encoders.items():\n",
    "    #         if col in new_df:\n",
    "    #             new_df[col] = new_df[col].map(lambda s: s if s in le.classes_ else \"<UNK>\")\n",
    "    #             le_classes = np.append(le.classes_, \"<UNK>\")\n",
    "    #             le.classes_ = le_classes\n",
    "    #             new_df[col] = le.transform(new_df[col].astype(str))\n",
    "\n",
    "    #     X_new = new_df[self.feature_cols]\n",
    "    #     return X_new\n",
    "\n",
    "    def predict_new(self, new_df):\n",
    "        if not self.pipeline:\n",
    "            raise ValueError(\"No pipeline loaded. Train or load a model first.\")\n",
    "        # Date feature engineering\n",
    "        new_df = new_df.copy()\n",
    "        new_df[\"date\"] = pd.to_datetime(new_df[\"date\"])\n",
    "        new_df[\"year\"] = new_df[\"date\"].dt.year\n",
    "        new_df[\"month\"] = new_df[\"date\"].dt.month\n",
    "        new_df[\"dayofweek\"] = new_df[\"date\"].dt.dayofweek\n",
    "        new_df = new_df.drop(columns=[\"date\"], errors=\"ignore\")\n",
    "        return self.best_model.predict(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54d93abe-c778-486e-8efe-684416bcb816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/raw/nigerian_food_prices_2002_2025.csv\", skiprows=[1])\n",
    "\n",
    "# # Inspect\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c994b6c7-2f9a-4991-8e56-4fc5b47561b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = AdvancePricePredictor(model_save_path=\"best_price_model.pkl\")\n",
    "# predictor = AdvancePricePredictor(target_column=\"price\", time_column=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d46384f-31dc-4441-a213-ef82e43dc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_result = predictor.train_and_select_best(df)\n",
    "# print(\"Best Model\", best_result['best_model'])\n",
    "# print(\"Performance\", best_result['metrics'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617197de-482c-4eb9-b1da-c0b9ba84651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison_df = predictor.get_model_comparison()\n",
    "# comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfbc2f05-596a-4678-8047-1f1abbc6a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = df.tail(10)\n",
    "# predictions = predictor.predict_prices(new_data)\n",
    "\n",
    "# print(\"Predicted Prices:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a70e33e-2d11-4e82-b470-e1d4eaf4783f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 256\n",
      "[LightGBM] [Info] Number of data points in the train set: 48452, number of used features: 128\n",
      "[LightGBM] [Info] Start training from score 5256.745966\n",
      "                          MAE         RMSE  R2 Score\n",
      "RandomForest      2489.575227  5391.772992  0.752258\n",
      "GradientBoosting  2623.988663  5713.382932  0.721822\n",
      "XGBoost           2498.315925  5396.919361  0.751785\n",
      "LightGBM          2499.253006  5408.687012  0.750701\n",
      "✅ Best model (RandomForest) saved as ../models/saved_models/food_price_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ola-dev\\Documents\\MyProjectFolder\\nigeria_food_prices\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ---------------- USAGE ---------------- #\n",
    "df = pd.read_csv(\"../data/raw/nigerian_food_prices_2002_2025.csv\", skiprows=[1])\n",
    "pipeline = PricePredictionPipeline(df)\n",
    "X, y = pipeline.preprocess()\n",
    "X_train, X_test, y_train, y_test = pipeline.split(X, y)\n",
    "results = pipeline.train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "print(results)\n",
    "pipeline.save_best_model(\"../models/saved_models/food_price_model.pkl\")   # Save with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2ac5048-f02b-48e6-a28e-f6b9c6acc5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded RandomForest from ../models/saved_models/food_price_model.pkl\n",
      "Predicted Price: [23467.6075]\n"
     ]
    }
   ],
   "source": [
    "# Later, for prediction on unseen data:\n",
    "pipeline.load_model(\"../models/saved_models/food_price_model.pkl\")\n",
    "new_data = pd.DataFrame([{\n",
    "    \"date\": \"2025-01-15\",\n",
    "    \"admin1\": \"Katsina\",\n",
    "    # \"admin2\": \"Jibia\",\n",
    "    \"market\": \"Jibia (CBM)\",\n",
    "    # \"market_id\": 1038,\n",
    "    # \"latitude\": 13.08,\n",
    "    # \"longitude\": 7.24,\n",
    "    \"category\": \"cereals and tubers\",\n",
    "    \"commodity\": \"Maize\",\n",
    "    # \"commodity_id\": 51,\n",
    "    \"unit\": \"50KG\",\n",
    "    # \"priceflag\": \"actual\",\n",
    "    \"pricetype\": \"Wholesale\",\n",
    "    \"currency\": \"NGN\",\n",
    "    # \"usdprice\": 1.54\n",
    "}])\n",
    "preds = pipeline.predict_new(new_data)\n",
    "print(\"Predicted Price:\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01157925-5c1b-47f7-ab1a-2f4310852c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of object saved: <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "Attributes available: ['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__sklearn_clone__', '__sklearn_is_fitted__', '__sklearn_tags__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_build_request_for_signature', '_can_fit_transform', '_can_inverse_transform', '_can_transform', '_check_method_params', '_doc_link_module', '_doc_link_template', '_doc_link_url_param_generator', '_estimator_type', '_final_estimator', '_fit', '_get_default_requests', '_get_doc_link', '_get_metadata_for_step', '_get_metadata_request', '_get_param_names', '_get_params', '_get_params_html', '_html_repr', '_iter', '_log_message', '_parameter_constraints', '_replace_estimator', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_set_params', '_sk_visual_block_', '_validate_names', '_validate_params', '_validate_steps', 'classes_', 'decision_function', 'feature_names_in_', 'fit', 'fit_predict', 'fit_transform', 'get_feature_names_out', 'get_metadata_routing', 'get_params', 'inverse_transform', 'memory', 'n_features_in_', 'named_steps', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'score_samples', 'set_output', 'set_params', 'set_score_request', 'steps', 'transform', 'transform_input', 'verbose']\n",
      "\n",
      "Pipeline steps:\n",
      "('preprocessor', ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['admin1', 'market', 'category', 'commodity',\n",
      "                                  'unit', 'pricetype', 'currency']),\n",
      "                                ('num', 'passthrough', [])]))\n",
      "('model', RandomForestRegressor(random_state=42))\n",
      "\n",
      "Model parameters:\n",
      "{'memory': None, 'steps': [('preprocessor', ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['admin1', 'market', 'category', 'commodity',\n",
      "                                  'unit', 'pricetype', 'currency']),\n",
      "                                ('num', 'passthrough', [])])), ('model', RandomForestRegressor(random_state=42))], 'transform_input': None, 'verbose': False, 'preprocessor': ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['admin1', 'market', 'category', 'commodity',\n",
      "                                  'unit', 'pricetype', 'currency']),\n",
      "                                ('num', 'passthrough', [])]), 'model': RandomForestRegressor(random_state=42), 'preprocessor__force_int_remainder_cols': 'deprecated', 'preprocessor__n_jobs': None, 'preprocessor__remainder': 'drop', 'preprocessor__sparse_threshold': 0.3, 'preprocessor__transformer_weights': None, 'preprocessor__transformers': [('cat', OneHotEncoder(handle_unknown='ignore'), ['admin1', 'market', 'category', 'commodity', 'unit', 'pricetype', 'currency']), ('num', 'passthrough', [])], 'preprocessor__verbose': False, 'preprocessor__verbose_feature_names_out': True, 'preprocessor__cat': OneHotEncoder(handle_unknown='ignore'), 'preprocessor__num': 'passthrough', 'preprocessor__cat__categories': 'auto', 'preprocessor__cat__drop': None, 'preprocessor__cat__dtype': <class 'numpy.float64'>, 'preprocessor__cat__feature_name_combiner': 'concat', 'preprocessor__cat__handle_unknown': 'ignore', 'preprocessor__cat__max_categories': None, 'preprocessor__cat__min_frequency': None, 'preprocessor__cat__sparse_output': True, 'model__bootstrap': True, 'model__ccp_alpha': 0.0, 'model__criterion': 'squared_error', 'model__max_depth': None, 'model__max_features': 1.0, 'model__max_leaf_nodes': None, 'model__max_samples': None, 'model__min_impurity_decrease': 0.0, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__min_weight_fraction_leaf': 0.0, 'model__monotonic_cst': None, 'model__n_estimators': 100, 'model__n_jobs': None, 'model__oob_score': False, 'model__random_state': 42, 'model__verbose': 0, 'model__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model file\n",
    "model_path = \"../models/saved_models/food_price_model.pkl\"\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "print(\"Type of object saved:\", type(model))\n",
    "print(\"\\nAttributes available:\", dir(model))\n",
    "\n",
    "# If it's a pipeline, check the steps\n",
    "if hasattr(model, \"steps\"):\n",
    "    print(\"\\nPipeline steps:\")\n",
    "    for step in model.steps:\n",
    "        print(step)\n",
    "\n",
    "# If it's RandomForest or another estimator\n",
    "if hasattr(model, \"get_params\"):\n",
    "    print(\"\\nModel parameters:\")\n",
    "    print(model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f5d7977-838e-49a1-a85d-5a60cb7d42ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of saved object: <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "✅ It's a pipeline. Steps inside:\n",
      " - preprocessor: ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['admin1', 'market', 'category', 'commodity',\n",
      "                                  'unit', 'pricetype', 'currency']),\n",
      "                                ('num', 'passthrough', [])])\n",
      " - model: RandomForestRegressor(random_state=42)\n",
      "\n",
      "Attributes / Methods available:\n",
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__sklearn_clone__', '__sklearn_is_fitted__', '__sklearn_tags__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_build_request_for_signature', '_can_fit_transform', '_can_inverse_transform', '_can_transform', '_check_method_params', '_doc_link_module', '_doc_link_template', '_doc_link_url_param_generator', '_estimator_type', '_final_estimator', '_fit', '_get_default_requests', '_get_doc_link', '_get_metadata_for_step']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load model\n",
    "model = joblib.load(\"../models/saved_models/food_price_model.pkl\")\n",
    "\n",
    "# Print type\n",
    "print(\"Type of saved object:\", type(model))\n",
    "\n",
    "# If it's a pipeline\n",
    "if hasattr(model, \"steps\"):\n",
    "    print(\"\\n✅ It's a pipeline. Steps inside:\")\n",
    "    for name, step in model.steps:\n",
    "        print(f\" - {name}: {step}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Not a pipeline. Likely a raw model:\")\n",
    "    print(model)\n",
    "\n",
    "# Print available attributes\n",
    "print(\"\\nAttributes / Methods available:\")\n",
    "print(dir(model)[:50])  # just first 50 to avoid too long output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
